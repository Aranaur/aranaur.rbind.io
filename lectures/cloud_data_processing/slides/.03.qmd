---
title: "GCP: Python —Ç–∞ BigQuery"
subtitle: "–•–º–∞—Ä–Ω—ñ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö"
author: "–Ü–≥–æ—Ä –ú—ñ—Ä–æ—à–Ω–∏—á–µ–Ω–∫–æ"
institute: –ö–ù–£ —ñ–º–µ–Ω—ñ –¢–∞—Ä–∞—Å–∞ –®–µ–≤—á–µ–Ω–∫–∞ | –§–Ü–¢
# date: today
# date-format: iso
from: markdown+emoji
title-slide-attributes:
  data-background-iframe: .01_files/libs/colored-particles/index.html
#   data-background-color: "#eef3f8"
lang: ua
footer: üîó <a href="https://aranaur.rbind.io/lectures/cloud_data_processing/">–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ –∫—É—Ä—Å—É</a>
format: 
  html:
    toc: true
    code-line-numbers: false
    highlight-style: github
    pdf-separate-fragments: true
    # fig-height: 7.5
    fig-width: 15
    fig-align: center
    fig-format: svg
    theme: [default, custom.scss]
jupyter: python3
execute: 
  warning: false
  echo: true
---

```{python}
#| label: setup
#| include: false
#| eval: false

# Import libraries
import numpy as np
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import norm, uniform, t

from IPython.display import Markdown
from tabulate import tabulate

# Set seaborn default style
sns.set_style('whitegrid')
sns.set_palette('colorblind')

# Define colors
red_pink   = "#e64173"
turquoise  = "#20B2AA"
orange     = "#FFA500"
red        = "#fb6107"
blue       = "#181485"
navy       = "#150E37FF"
green      = "#8bb174"
yellow     = "#D8BD44"
# grey_light = "grey70"
# grey_mid   = "grey50"
# grey_dark  = "grey20"
purple     = "#6A5ACD"
slate      = "#314f4f"
```

## –í–∏–º–æ–≥–∏

1. –ê–∫—Ç–∏–≤—É–≤–∞—Ç–∏ BigQuery API –≤ –∫–æ–Ω—Å–æ–ª—ñ GCP
2. –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É `google-cloud-bigquery`:

```bash
pip install --upgrade google-cloud-bigquery
pip install google-cloud-bigquery-datatransfer
pip install db-dtypes
```

3. –°—Ç–≤–æ—Ä–∏—Ç–∏ —Å–µ—Ä–≤—ñ—Å–Ω–∏–π –∫–ª—é—á –¥–ª—è –¥–æ—Å—Ç—É–ø—É –¥–æ BigQuery API (Role: Basic, Roles: Owner) —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –π–æ–≥–æ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–∏–π –∫–æ–º–ø'—é—Ç–µ—Ä.

## –ü–æ—á–∞—Ç–æ–∫ —Ä–æ–±–æ—Ç–∏ –∑ API

```{python}
#| label: bigquery-setup

import os
from google.cloud import bigquery, bigquery_datatransfer
import google.auth
import time
import pandas as pd
import datetime
import json

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å–µ—Ä–≤—ñ—Å–Ω–æ–≥–æ –∫–ª—é—á–∞
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "./data/fit-cloud-course-key.json"
```

### –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–ª—ñ—î–Ω—Ç–∞

```{python}
#| label: client

client = bigquery.Client('fit-cloud-course')
```

### –ó–∞–ø–∏—Ç–∏ –¥–æ BigQuery

```{python}
#| label: query

sql_query = """
SELECT station_id, name, dockcount
FROM `bigquery-public-data.san_francisco.bikeshare_stations`
LIMIT 5
"""
```

### –í–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—É

```{python}
#| label: execute

query_job = client.query(sql_query)

print(query_job)
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–∞–ø–∏—Ç—É

```{python}
#| label: results-1

for row in query_job:
    print(row)
```

```{python}
#| label: results-2

for row in query_job:
    print(row[0], row[1], row[2], sep=" | ")
```

```{python}
#| label: results-3

for row in query_job:
    print(row.station_id, row.name, row.dockcount, sep=" | ")
```

## –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –≤ BigQuery

### JSON

–ó–∞ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ, –ø–µ—Ä–µ–≤–µ–¥–µ–º–æ –¥–∞–Ω—ñ —É –ø–ª–æ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç:

```{python}
#| label: flatten
#| eval: false

json_data = json.load(open('./data/orders.json'))
data_file_path = './data/orders_upload.json'

with open(data_file_path, 'w') as f:
    f.write('\n'.join(json.dumps(record) for record in json_data))
```

```{python}
#| label: upload-setup

dataset_id = 'dsongcp'
table_id = 'orders'
data_file_path = './data/orders.json'
```

```{python}
#| label: upload-config

job_config = bigquery.LoadJobConfig(
    schema=[
        bigquery.SchemaField("order_id", "INT64"),
        bigquery.SchemaField("creation_time", "DATETIME"),
        bigquery.SchemaField("product_ids", "INT64", mode="REPEATED"),
        ],
    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,
    autodetect=False,    
    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE
)
```

```{python}
#| label: upload-execute

table_ref = client.dataset(dataset_id).table(table_id)
with open(data_file_path, "rb") as source_file:
    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)

while job.running():
    print('–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...')
    time.sleep(3)
print(job.result())
```

### GC Storage

```{python}
#| label: storage-upload

bucket_name = 'fit-cloud-course-dsongcp'
source_uri = f"gs://{bucket_name}/flights/raw/*.csv"
table_id = 'flights_py'
```

```{python}
#| label: storage-config-2

job_config = bigquery.LoadJobConfig(
    autodetect=True,
    source_format=bigquery.SourceFormat.CSV,
    skip_leading_rows=1,
    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE
)
```

```{python}
#| label: storage-execute-2

table_ref = client.dataset(dataset_id).table(table_id)
job = client.load_table_from_uri(
    source_uri,
    table_ref,
    job_config=job_config
)

while job.running():
    print('–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...')
    time.sleep(3)
print(job.result())
```

### CSV

```{python}
#| label: csv-upload

dataset_id = 'dsongcp'
table_id = 'users'
data_file_path = './data/users.csv'

job_config = bigquery.LoadJobConfig(
    source_format=bigquery.SourceFormat.CSV,
    skip_leading_rows=1,
    autodetect=True,
    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE
)

table_ref = client.dataset(dataset_id).table(table_id)
with open(data_file_path, "rb") as source_file:
    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)

while job.running():
    print('–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...')
    time.sleep(3)
print(job.result())
```

```{python}
#| label: csv-rows-cols

table = client.get_table(table_ref)
print(f"–¢–∞–±–ª–∏—Ü—è: {table}\n–°–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω—å: {table.num_rows}\n–ó–º—ñ–Ω–Ω–∏—Ö: {len(table.schema)}")
```

### Google Sheets

–ü—ñ–¥–∫–ª—é—á–∞—î–º–æ Google Drive API.
–ö–æ–ø—ñ—é—î–º–æ email-–∞–¥—Ä–µ—Å—É —Å–µ—Ä–≤—ñ—Å–Ω–æ–≥–æ –∞–∫–∞—É–Ω—Ç–∞.

```{python}
#| label: sheets-setup

credentials, project = google.auth.default(
    scopes=[
      "https://www.googleapis.com/auth/drive",
      "https://www.googleapis.com/auth/bigquery"
    ]
)
```

```{python}
#| label: sheets-config

client = bigquery.Client(credentials=credentials, project=project)

dataset_id = 'dsongcp'
table_id = 'air_traffic'
table_ref = client.dataset(dataset_id).table(table_id)
```

```{python}
#| label: sheets-execute

table = bigquery.Table(table_ref, schema = [
    bigquery.SchemaField("Activity_Period", "INT64"),
    bigquery.SchemaField("Activity_Period_Start_Date", "DATE"),
    bigquery.SchemaField("Operating_Airline", "STRING"),
    bigquery.SchemaField("Operating_Airline_IATA_Code", "STRING"),
    bigquery.SchemaField("Published_Airline", "STRING"),
    bigquery.SchemaField("Published_Airline_IATA_Code", "STRING"),
    bigquery.SchemaField("GEO_Summary", "STRING"),
    bigquery.SchemaField("GEO_Region", "STRING"),
    bigquery.SchemaField("Activity_Type_Code", "STRING"),
    bigquery.SchemaField("Price_Category_Code", "STRING"),
    bigquery.SchemaField("Terminal", "STRING"),
    bigquery.SchemaField("Boarding_Area", "STRING"),
    bigquery.SchemaField("Passenger_Count", "INT64"),
    bigquery.SchemaField("data_as_of", "STRING"),
    bigquery.SchemaField("data_loaded_at", "STRING")
])

external_config = bigquery.ExternalConfig("GOOGLE_SHEETS")
sheet_url = "https://docs.google.com/spreadsheets/d/1vp7bCvxd3R2zciqxc8A4Qoq5DAvqhzfXJnljmG5OOw0/edit?usp=sharing"
external_config.source_uris = [sheet_url]

options = external_config.google_sheets_options
options.skip_leading_rows = 1
options.range = "air_traffic!A:O"

table.external_data_configuration = external_config
client.create_table(table)
```

## –ú—ñ—Ç–∫–∏ –¥–∞–Ω–∏—Ö —É BigQuery

–ú—ñ—Ç–∫–∞ ‚Äì —Ü–µ –ø–∞—Ä–∞ –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–Ω—è, —è–∫—É –º–æ–∂–Ω–∞ –ø—Ä–∏–∑–Ω–∞—á–∏—Ç–∏ —Ä–µ—Å—É—Ä—Å–∞–º Google Cloud BigQuery. –í–∏ –º–æ–∂–µ—Ç–µ –ø—Ä–∏–∫—Ä—ñ–ø–∏—Ç–∏ –º—ñ—Ç–∫—É –¥–æ –∫–æ–∂–Ω–æ–≥–æ —Ä–µ—Å—É—Ä—Å—É, –∞ –ø–æ—Ç—ñ–º –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä—É–≤–∞—Ç–∏ —Ä–µ—Å—É—Ä—Å–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ó—Ö–Ω—ñ—Ö –º—ñ—Ç–æ–∫.

–û—Å—å –∫—ñ–ª—å–∫–∞ —Ç–∏–ø–æ–≤–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –º—ñ—Ç–æ–∫:

- **–ú—ñ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥–∏:** `team:research` –∞–±–æ `team:analytics`.
- **–ú—ñ—Ç–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤:** –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, `component:redis`, `component:frontend`, `component:ingest—Ç–∞`, `component:dashboard` —Ç–æ—â–æ.
- **–ú—ñ—Ç–∫–∏ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞:** `environment:production` —ñ `environment:test`.
- **–ú—ñ—Ç–∫–∏ —Å—Ç–∞–Ω—É:** `state:active`, `state:readytodelete` —ñ `state:archive`.
- **–ú—ñ—Ç–∫–∏ –≤–ª–∞—Å–Ω–æ—Å—Ç—ñ:** –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–ª—è —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∫–æ–º–∞–Ω–¥, —è–∫—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é—Ç—å –∑–∞ –æ–ø–µ—Ä–∞—Ü—ñ—ó, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥ `team:shopping-cart`.

### –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ

```{python}
#| label: create-table-1

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Ç–∞–±–ª–∏—Ü—é
dataset_ref = bigquery.DatasetReference(client.project, 'dsongcp')

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ
table_ref = bigquery.TableReference(dataset_ref, 'flights_auto')
```

### –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º—ñ—Ç–æ–∫

```{python}
#| label: labels

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º—ñ—Ç–æ–∫
labels = {
    'type': 'auto',
    'category': 'transport'
}

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ –∑ –º—ñ—Ç–∫–∞–º–∏
flights_auto_table = client.get_table(table_ref)
# –î–æ–¥–∞–≤–∞–Ω–Ω—è –º—ñ—Ç–æ–∫
flights_auto_table.labels = labels
# –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ
client.update_table(flights_auto_table, ['labels'])
```

### –û–Ω–æ–≤–ª–µ–Ω–Ω—è –º—ñ—Ç–æ–∫

```{python}
#| label: update-labels

# –û–Ω–æ–≤–ª–µ–Ω–Ω—è –º—ñ—Ç–æ–∫
new_labels = {
    'type': 'auto',
    'category': 'transport',
    'year': '2015'
}

flights_auto_table = client.get_table(table_ref)
flights_auto_table.labels = new_labels
client.update_table(flights_auto_table, ['labels'])
```

### –í–∏–¥–∞–ª–µ–Ω–Ω—è –º—ñ—Ç–æ–∫

```{python}
#| label: delete-labels

table = client.get_table(table_ref)
labels = table.labels
labels = {k: None for k, v in labels.items()}
table.labels = labels
client.update_table(table, ['labels'])
```

## –î–æ–¥–∞–≤–∞–Ω–Ω—è/–≤–∏–¥–∞–ª–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö

```{python}
#| label: columns

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ
dataset_ref = bigquery.DatasetReference(client.project, 'dsongcp')
table_ref = bigquery.TableReference(dataset_ref, 'flights_auto')
bigquery_table = client.get_table(table_ref)
```

–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ö–µ–º–∏ —Ç–∞–±–ª–∏—Ü—ñ:

```{python}
#| label: schema

schema = bigquery_table.schema
schema[:5]
```

–°—Ç–≤–æ—Ä–∏–º–æ –∫–æ–ø—ñ—é —Å—Ö–µ–º–∏:

```{python}
#| label: copy-schema

new_schema = schema.copy()
```

–î–æ–¥–∞–º–æ –Ω–æ–≤—É –∑–º—ñ–Ω–Ω—É —É —Å—Ö–µ–º—É:

```{python}
#| label: add-column

new_schema.append(bigquery.SchemaField('Distance_km', 'FLOAT64', mode='NULLABLE'))
# –ü–µ—Ä–µ–¥–∞–º–æ –æ–Ω–æ–≤–ª–µ–Ω—É —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ñ bigquery_table
bigquery_table.schema = new_schema
```

::: callout-note
–¢–∏–ø–∏ –¥–∞–Ω–∏—Ö –≤ BigQuery: <https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types>.
:::

–¢–µ–ø–µ—Ä –∑—Ä–æ–±–∏–º–æ –∑–∞–ø–∏—Ç –Ω–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ:

```{python}
#| label: update-schema

client.update_table(bigquery_table, ['schema'])
```

–ü–µ—Ä–µ–≥–ª—è–Ω–µ–º–æ –æ–Ω–æ–≤–ª–µ–Ω—É —Å—Ö–µ–º—É:

```{python}
#| label: updated-schema

bigquery_table = client.get_table(table_ref)
schema = bigquery_table.schema
schema[-5:]
```

–í–∏–¥–∞–ª–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–æ—ó –∑ —Å—Ö–µ–º–∏:

```{python}
#| label: delete-column

query_job = client.query("""
    ALTER TABLE dsongcp.flights_auto
    DROP COLUMN IF EXISTS Distance_km;
""")
```

–Ü–Ω–æ–¥—ñ –∑–∞–ø–∏—Ç –º–æ–∂–µ –∑–∞–π–º–∞—Ç–∏ –¥–µ—è–∫–∏–π —á–∞—Å –Ω–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è. –©–æ–± –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Å—Ç–∞—Ç—É—Å –∑–∞–ø–∏—Ç—É, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –º–µ—Ç–æ–¥ `query_job.state`:

```{python}
#| label: query-status

while query_job.state != 'DONE': 
    print('–ó–∞–ø–∏—Ç –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è...')
    time.sleep(3)
    query_job.reload()
print(query_job.result())
```

## –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∑–∞–ø–∏—Ç—É –≤ —Ç–∞–±–ª–∏—Ü—é

–ù–∞–ø–∏—à–µ–º–æ –∑–∞–ø–∏—Ç, —è–∫–∏–π –≤–∏–±–µ—Ä–µ —Å–µ—Ä–µ–¥–Ω—é –∑–∞—Ç—Ä–∏–º–∫—É –≤–∏–ª—å–æ—Ç—É —Ç–∞ –ø—Ä–∏–±—É—Ç—Ç—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∞–µ—Ä–æ–ø–æ—Ä—Ç—É –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:

```{python}
#| label: base-query

sql_query = """
SELECT
  ORIGIN,
  AVG(DepDelay) AS dep_delay,
  AVG(ArrDelay) AS arr_delay,
  COUNT(ArrDelay) AS num_flights
FROM
  `dsongcp.flights_auto`
GROUP BY
  ORIGIN
ORDER BY num_flights DESC
LIMIT 10
"""
```

–°—Ç–≤–æ—Ä–∏–º–æ –æ–∫—Ä–µ–º–∏–π –¥–∞—Ç–∞—Å–µ—Ç, –∫—É–¥–∏ –º–∏ –∑–±–µ—Ä–µ–∂–µ–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–∞–ø–∏—Ç—É:

```{python}
#| label: create-dataset

dataset_id = client.project + '.dsongcp_results'
dataset = bigquery.Dataset(dataset_id)
dataset.location = "US"
dataset = client.create_dataset(dataset, exists_ok=True)
print(f"–°—Ç–≤–æ—Ä–µ–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç {client.project}.{dataset.dataset_id}")
```

–í–∏–∑–Ω–∞—á–∏–º–æ —Ç–∞–±–ª–∏—Ü—é, –≤ —è–∫—É –º–∏ –∑–±–µ—Ä–µ–∂–µ–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–∞–ø–∏—Ç—É:

```{python}
#| label: table-info

project_id = client.project
dataset_id = 'dsongcp_results'
table_id = 'flights_delay'
```

–í–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –º–µ—Ç–æ–¥ `from_string()` –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ —Ç–∞–±–ª–∏—Ü—é:

```{python}
#| label: create-table-2

table_ref = bigquery.TableReference.from_string(f"{project_id}.{dataset_id}.{table_id}")
table_ref
```

–í–∏–∫–æ–Ω–∞—î–º–æ –∑–∞–ø–∏—Ç —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤ —Ç–∞–±–ª–∏—Ü—é:

```{python}
#| label: save-results

job_config = bigquery.QueryJobConfig(destination=table_ref, write_disposition="WRITE_TRUNCATE")
query_job = client.query(sql_query, job_config=job_config)
while query_job.state != 'DONE': 
    print('–ó–∞–ø–∏—Ç –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è...')
    time.sleep(3)
    query_job.reload()
print(query_job.result())
```

::: callout-note
–ë—ñ–ª—å—à–µ –ø—Ä–æ `QueryJobConfig` –∑–∞ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º <https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.job.QueryJobConfig>
:::

## –ó–∞–ø–∏—Ç —É DataFrame

–î–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ —Ä–æ–±–æ—Ç–∏ –∑ –¥–∞–Ω–∏–º–∏ –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É `pandas`. –î–ª—è —Ü—å–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –º–µ—Ç–æ–¥ `to_dataframe()`:

```{python}
#| label: to-dataframe

query_job = client.query(sql_query)
df = query_job.to_dataframe()
df
```

## –ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω—ñ –∑–∞–ø–∏—Ç–∏

–ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω—ñ –∑–∞–ø–∏—Ç–∏ –¥–æ–∑–≤–æ–ª—è—é—Ç—å –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –∑–º—ñ–Ω–Ω—ñ –≤ –∑–∞–ø–∏—Ç–∞—Ö. –¶–µ –¥–æ–∑–≤–æ–ª—è—î –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –æ–¥–∏–Ω —ñ —Ç–æ–π –∂–µ –∑–∞–ø–∏—Ç –∑ —Ä—ñ–∑–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ –∑–º—ñ–Ω–Ω–∏—Ö.

–î–ª—è —Ü—å–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —Å–∏–º–≤–æ–ª `@` –ø–µ—Ä–µ–¥ –∑–º—ñ–Ω–Ω–æ—é –≤ –∑–∞–ø–∏—Ç—ñ. –í–∏–∑–Ω–∞—á–∏–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä `month` —Ç–∞ –≤–∏–∫–æ–Ω–∞—î–º–æ –∑–∞–ø–∏—Ç:

```{python}
#| label: query-params

query_params = [
    bigquery.ScalarQueryParameter("month", "INT64", 1)
]
```

```{python}
#| label: param-query

sql_query = """
SELECT
  ORIGIN,
  AVG(DepDelay) AS dep_delay,
  AVG(ArrDelay) AS arr_delay,
  COUNT(ArrDelay) AS num_flights
FROM
  `dsongcp.flights_auto`
WHERE
  Month = @month
GROUP BY
  ORIGIN
ORDER BY num_flights DESC
LIMIT 10
"""
```

```{python}
#| label: execute-params

job_config = bigquery.QueryJobConfig(query_parameters=query_params)
query_job = client.query(sql_query, job_config=job_config)
df = query_job.to_dataframe()
df
```

–£ –≤–∏–ø–∞–¥–∫—É –∫–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –∑—Ä—ñ–∑ –ø–æ –¥–∞—Ç—ñ:

```{python}
#| label: date-params

query_params = [
    bigquery.ScalarQueryParameter("start_date", "DATE", datetime.date(2015, 1, 1)),
    bigquery.ScalarQueryParameter("end_date", "DATE", datetime.date(2015, 1, 7))
]
```

–¢–æ–¥—ñ –∑–∞–ø–∏—Ç –±—É–¥–µ –≤–∏–≥–ª—è–¥–∞—Ç–∏ –Ω–∞—Å—Ç—É–ø–Ω–∏–º —á–∏–Ω–æ–º:

```{python}
#| label: date-query

sql_query = """
SELECT
  ORIGIN,
  AVG(DepDelay) AS dep_delay,
  AVG(ArrDelay) AS arr_delay,
  COUNT(ArrDelay) AS num_flights
FROM
  `dsongcp.flights_auto`
WHERE
  FlightDate BETWEEN @start_date AND @end_date
GROUP BY
  ORIGIN
ORDER BY num_flights DESC
LIMIT 10
"""
```

```{python}
#| label: execute-date

job_config = bigquery.QueryJobConfig(query_parameters=query_params)
query_job = client.query(sql_query, job_config=job_config)
df = query_job.to_dataframe()
df
```

–Ü —Ç—Ä–µ—Ç—ñ–π –≤–∞—Ä—ñ–∞–Ω—Ç - –ø–æ–∑–∏—Ü—ñ–π–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏:

```{python}
#| label: positional-params

query_params = [
    bigquery.ScalarQueryParameter(None, "FLOAT64", 0),
    bigquery.ScalarQueryParameter(None, "FLOAT64", 0)

]
```

```{python}
#| label: positional-query

sql_query = """
SELECT
  ORIGIN,
  AVG(DepDelay) AS dep_delay,
  AVG(ArrDelay) AS arr_delay,
  COUNT(ArrDelay) AS num_flights
FROM
  `dsongcp.flights_auto`
WHERE
  DepDelay < ? AND ArrDelay < ?
GROUP BY
  ORIGIN
ORDER BY num_flights DESC
LIMIT 10
"""
```

```{python}
#| label: execute-positional

job_config = bigquery.QueryJobConfig(query_parameters=query_params)
query_job = client.query(sql_query, job_config=job_config)
df = query_job.to_dataframe()
df
```

–©–µ –æ–¥–∏–Ω –≤–∞—Ä—ñ–∞–Ω—Ç - –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –º–∞—Å–∏–≤—ñ–≤:

```{python}
#| label: array-params

query_params = [
    bigquery.ArrayQueryParameter("ORIGIN", "STRING", ["PHX", "ATL", "LAS"]),
    bigquery.ScalarQueryParameter("DepDelay", "FLOAT64", 10),
]
```

```{python}
#| label: array-query

sql_query = """
SELECT
  ORIGIN,
  AVG(DepDelay) AS dep_delay,
  AVG(ArrDelay) AS arr_delay,
  COUNT(ArrDelay) AS num_flights
FROM
  `dsongcp.flights_auto`
WHERE
  ORIGIN IN UNNEST(@ORIGIN)
  AND DepDelay > @DepDelay
GROUP BY
  ORIGIN
ORDER BY num_flights DESC
"""
```

```{python}
#| label: execute-array

job_config = bigquery.QueryJobConfig(query_parameters=query_params)
query_job = client.query(sql_query, job_config=job_config)
df = query_job.to_dataframe()
df
```

## –¢–∞–±–ª–∏—Ü—è BG -> GC Storage

```{python}
#| label: storage-setup

client = bigquery.Client('fit-cloud-course')
dataset_id = 'dsongcp'
bucket_name = 'fit-cloud-course-dsongcp'
```

```{python}
#| label: storage-results

table_ref = bigquery.TableReference.from_string(f"{client.project}.{dataset_id}.flights_auto")
```

```{python}
#| label: storage-config

job_config = bigquery.job.ExtractJobConfig()
# job_config.destination_format = bigquery.DestinationFormat.CSV
job_config.destination_format = bigquery.DestinationFormat.NEWLINE_DELIMITED_JSON
```

```{python}
#| label: storage-execute

destination_uri = f"gs://{bucket_name}/results/flights_delay.json"

extract_job = client.extract_table(
    table_ref,
    destination_uri,
    job_config=job_config,
    location="US"
)
extract_job.result()
```

## –†–æ–±–æ—Ç–∞ –∑ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏

–ü—ñ–¥–∫–ª—é—á—ñ—Ç—å **BigQuery Data Transfer API**.

–°—Ç–≤–æ—Ä–∏–º–æ –∫–ª–∞—Å `DatasetManager` –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏:

```{python}
#| label: dataset-manager

class DatasetManager:
    def __init__(self, client):
        self.client = client

    def delete_dataset(self, dataset_id):
        self.client.delete_dataset(dataset_id, not_found_ok=True, delete_contents=True)

    def create_dataset(self, dataset_id, location='US'):
        dataset = bigquery.Dataset(dataset_id)
        dataset.location = location
        dataset_ = self.client.create_dataset(dataset, timeout=30)
        print(f"–î–∞—Ç–∞—Å–µ—Ç {self.client.project}.{dataset.dataset_id} —Å—Ç–≤–æ—Ä–µ–Ω–æ")
        return dataset_

    def list_dataset(self):
        datasets = self.client.list_datasets()
        return [dataset.dataset_id for dataset in datasets]

    def copy_dataset(self, source_project_id, source_dataset_id, destination_project_id, destination_dataset_id, display_name):
        """
        –ü–æ—Å–∏–ª–∞–Ω–Ω—è:
        https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.transferConfigs

        –ù–∞–¥–∞—Ç–∏ –¥–æ—Å—Ç—É–ø –¥–æ IAM:
        https://cloud.google.com/bigquery/docs/enable-transfer-service#grant_bigqueryadmin_access

        –ó–∞—É–≤–∞–∂—Ç–µ:
        - —Ü–µ —Ç–∞–∫–æ–∂ –ø—Ä–∏–∑–≤–µ–¥–µ –¥–æ –ø–µ—Ä–µ–º—ñ—â–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—å.
        - –ø—ñ–¥–∫–ª—é—á—ñ—Ç—å BigQuery Data Transfer API.
        """
        transfer_client = bigquery_datatransfer.DataTransferServiceClient()
        transfer_config = bigquery_datatransfer.TransferConfig(
            destination_dataset_id=destination_dataset_id,
            display_name=display_name,
            data_source_id="cross_region_copy", # 
            params={
                "source_project_id": source_project_id,
                "source_dataset_id": source_dataset_id,
            },
        )
        transfer_config = transfer_client.create_transfer_config(
            parent=transfer_client.common_project_path(destination_project_id),
            transfer_config=transfer_config,
        )
        print(f"–°—Ç–≤–æ—Ä–µ–Ω–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –ø–µ—Ä–µ–¥–∞—á—ñ: {transfer_config.name}")
```

–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –∫–ª—ñ—î–Ω—Ç —Ç–∞ –∫–ª–∞—Å:

```{python}
#| label: dataset-init

client = bigquery.Client('fit-cloud-course')
dataset_manager = DatasetManager(client)
```

–í–∏–≤–µ–¥–µ–º–æ —Å–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤:

```{python}
#| label: list-datasets

dataset_manager.list_dataset()
```

–°—Ç–≤–æ—Ä–∏–º–æ –Ω–æ–≤–∏–π –¥–∞—Ç–∞—Å–µ—Ç:

```{python}
#| label: create-dataset-2

dataset_name = f'{client.project}.ny_taxi_trips'
dataset = dataset_manager.create_dataset(dataset_name)
```

–°–∫–æ–ø—ñ—é—î–º–æ –¥–∞—Ç–∞—Å–µ—Ç:

```{python}
#| label: copy-dataset

source_project_id = 'bigquery-public-data'
source_dataset_id = 'new_york_taxi_trips'
destination_project_id = client.project
destination_dataset_id = 'ny_taxi_trips'
display_name = 'NY Taxi Trips'

dataset_manager.copy_dataset(source_project_id, source_dataset_id, destination_project_id, destination_dataset_id, display_name)
```

–í–∏–¥–∞–ª–∏–º–æ –¥–∞—Ç–∞—Å–µ—Ç:

```{python}
#| label: delete-dataset

dataset_manager.delete_dataset(dataset_name)
```
