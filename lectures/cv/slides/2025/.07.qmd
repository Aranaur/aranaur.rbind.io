---
title: "–†–µ–ø–ª—ñ–∫–∞—Ü—ñ—è —Å—Ç–∞—Ç—Ç—ñ –∑ üî•PyTorch"
subtitle: "–¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó –∫–æ–º–ø'—é—Ç–µ—Ä–Ω–æ–≥–æ –∑–æ—Ä—É"
author: "–Ü–≥–æ—Ä –ú—ñ—Ä–æ—à–Ω–∏—á–µ–Ω–∫–æ"
institute: –ö–ù–£ —ñ–º–µ–Ω—ñ –¢–∞—Ä–∞—Å–∞ –®–µ–≤—á–µ–Ω–∫–∞, –§–Ü–¢
from: markdown+emoji
title-slide-attributes:
    data-background-iframe: .07_files/libs/colored-particles/index.html
language: _language-ua.yml
footer: <a href="https://aranaur.rbind.io/lectures">üîó–¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó –∫–æ–º–ø'—é—Ç–µ—Ä–Ω–æ–≥–æ –∑–æ—Ä—É</a>
format:
  revealjs: 
    transition: fade
    chalkboard: true
    logo: fit.png
    slide-number: true
    # toc: true
    # toc-depth: 1
    mouse-wheel: true
    width: 1350  
    height: 759.375
    highlight-style: github
    fig-width: 9
    fig-height: 5
    fig-format: svg
    fig-align: center
    theme: [default, custom.scss]
#   gfm:
#     mermaid-format: png
preload-iframes: true
jupyter: python3
execute: 
  echo: true
  warning: false
editor_options: 
  chunk_output_type: console
---

```{python}
#| include: false

# Define colors
red_pink   = "#e64173"
turquoise  = "#20B2AA"
orange     = "#FFA500"
red        = "#fb6107"
blue       = "#181485"
navy       = "#150E37FF"
green      = "#8bb174"
yellow     = "#D8BD44"
purple     = "#6A5ACD"
slate      = "#314f4f"
```

## –©–æ —Ç–∞–∫–µ —Ä–µ–ø–ª—ñ–∫–∞—Ü—ñ—è –Ω–∞—É–∫–æ–≤–æ—ó —Å—Ç–∞—Ç—Ç—ñ?

- –†–µ–ø–ª—ñ–∫–∞—Ü—ñ—è (–≤—ñ–¥ –∞–Ω–≥–ª. replication) --- —Ü–µ –ø—Ä–æ—Ü–µ—Å **–≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è** —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –Ω–∞—É–∫–æ–≤–æ–≥–æ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ç–∏—Ö —Å–∞–º–∏—Ö –º–µ—Ç–æ–¥—ñ–≤, –¥–∞–Ω–∏—Ö —Ç–∞ —É–º–æ–≤, —â–æ –π —É –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–º—É –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—ñ.
- –¶–µ –¥–æ–∑–≤–æ–ª—è—î –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—ñ **–Ω–æ–≤–∏–Ω–∫–∏** –≤ –Ω–∞—É–∫–æ–≤–∏—Ö –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è—Ö, –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —ó—Ö–Ω—é –¥–æ—Å—Ç–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å —Ç–∞ **–∑—Ä–æ–∑—É–º—ñ—Ç–∏**, —è–∫ –≤–æ–Ω–∏ –ø—Ä–∞—Ü—é—é—Ç—å –Ω–∞ –ø—Ä–∞–∫—Ç–∏—Ü—ñ.
- –†–µ–ø–ª—ñ–∫–∞—Ü—ñ—è —î –≤–∞–∂–ª–∏–≤–æ—é —á–∞—Å—Ç–∏–Ω–æ—é –Ω–∞—É–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—É, –æ—Å–∫—ñ–ª—å–∫–∏ –≤–æ–Ω–∞ –¥–æ–ø–æ–º–∞–≥–∞—î **–ø—ñ–¥—Ç–≤–µ—Ä–¥–∏—Ç–∏** –∞–±–æ **—Å–ø—Ä–æ—Å—Ç—É–≤–∞—Ç–∏** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å, –∞ —Ç–∞–∫–æ–∂ —Å–ø—Ä–∏—è—î —Ä–æ–∑–≤–∏—Ç–∫—É –Ω–æ–≤–∏—Ö —ñ–¥–µ–π —Ç–∞ –º–µ—Ç–æ–¥—ñ–≤.

## –ó —á–æ–≥–æ —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è —Å—Ç–∞—Ç—Ç—è? {.smaller}

- **–ê–Ω–æ—Ç–∞—Ü—ñ—è** (Abstract): –ö–æ—Ä–æ—Ç–∫–∏–π –æ–≥–ª—è–¥ –æ—Å–Ω–æ–≤–Ω–∏—Ö —Ü—ñ–ª–µ–π, –º–µ—Ç–æ–¥—ñ–≤, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —Ç–∞ –≤–∏—Å–Ω–æ–≤–∫—ñ–≤ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è.
- **–í—Å—Ç—É–ø** (Introduction): –û–ø–∏—Å –ø—Ä–æ–±–ª–µ–º–∏, –æ–≥–ª—è–¥ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏ —Ç–∞ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ü—ñ–ª–µ–π –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è.
- **–ú–µ—Ç–æ–¥–æ–ª–æ–≥—ñ—è** (Methodology): –î–µ—Ç–∞–ª—å–Ω–∏–π –æ–ø–∏—Å –º–µ—Ç–æ–¥—ñ–≤, —è–∫—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–ª–∏—Å—è –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è.
- **–†–µ–∑—É–ª—å—Ç–∞—Ç–∏** (Results): –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è, —á–∞—Å—Ç–æ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ç–∞–±–ª–∏—Ü—å —Ç–∞ –≥—Ä–∞—Ñ—ñ–∫—ñ–≤.
- **–í–∏—Å–Ω–æ–≤–∫–∏** (Conclusion): –ü—ñ–¥—Å—É–º–æ–∫ –æ—Å–Ω–æ–≤–Ω–∏—Ö –≤–∏—Å–Ω–æ–≤–∫—ñ–≤ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è —Ç–∞ —ó—Ö –∑–Ω–∞—á–µ–Ω–Ω—è.
- **–ü–æ—Å–∏–ª–∞–Ω–Ω—è** (References): –°–ø–∏—Å–æ–∫ –¥–∂–µ—Ä–µ–ª, —è–∫—ñ –±—É–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –≤ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—ñ.
- **–î–æ–¥–∞—Ç–∫–∏** (Appendices): –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è, —è–∫–∞ –º–æ–∂–µ –±—É—Ç–∏ –∫–æ—Ä–∏—Å–Ω–æ—é –¥–ª—è —Ä–æ–∑—É–º—ñ–Ω–Ω—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è, –∞–ª–µ –Ω–µ —î –∫—Ä–∏—Ç–∏—á–Ω–æ—é –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É.

## –î–µ —à—É–∫–∞—Ç–∏ —Å—Ç–∞—Ç—Ç—ñ?

- [arXiv](https://arxiv.org/) --- –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–∏–π –∞—Ä—Ö—ñ–≤ –Ω–∞—É–∫–æ–≤–∏—Ö —Å—Ç–∞—Ç–µ–π –∑ —Ä—ñ–∑–Ω–∏—Ö –≥–∞–ª—É–∑–µ–π –Ω–∞—É–∫–∏, –≤–∫–ª—é—á–∞—é—á–∏ –∫–æ–º–ø'—é—Ç–µ—Ä–Ω—ñ –Ω–∞—É–∫–∏, —Ñ—ñ–∑–∏–∫—É, –º–∞—Ç–µ–º–∞—Ç–∏–∫—É —Ç–∞ —ñ–Ω—à—ñ.
- [Google Scholar](https://scholar.google.com/) --- –ø–æ—à—É–∫–æ–≤–∞ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –Ω–∞—É–∫–æ–≤–∏—Ö —Å—Ç–∞—Ç–µ–π, –¥–∏—Å–µ—Ä—Ç–∞—Ü—ñ–π, –∫–Ω–∏–≥ —Ç–∞ —ñ–Ω—à–∏—Ö –∞–∫–∞–¥–µ–º—ñ—á–Ω–∏—Ö —Ä–µ—Å—É—Ä—Å—ñ–≤.
- [Hugging Face Papers with Code](https://huggingface.co/papers/trending) --- –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞, —è–∫–∞ –Ω–∞–¥–∞—î –¥–æ—Å—Ç—É–ø –¥–æ –Ω–∞—É–∫–æ–≤–∏—Ö —Å—Ç–∞—Ç–µ–π –∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏–º –∫–æ–¥–æ–º, —â–æ –¥–æ–∑–≤–æ–ª—è—î –ª–µ–≥–∫–æ –∑–Ω–∞—Ö–æ–¥–∏—Ç–∏ —Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –Ω–æ–≤—ñ—Ç–Ω—ñ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –≤ –≥–∞–ª—É–∑—ñ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.
- [GitHub](https://github.com/lucidrains/vit-pytorch) --- –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —Ö–æ—Å—Ç–∏–Ω–≥—É —Ç–∞ —Å–ø—ñ–ª—å–Ω–æ—ó —Ä–æ–±–æ—Ç–∏ –Ω–∞–¥ –ø—Ä–æ–µ–∫—Ç–∞–º–∏, —è–∫–∞ —Ç–∞–∫–æ–∂ –º—ñ—Å—Ç–∏—Ç—å –±–∞–≥–∞—Ç–æ –Ω–∞—É–∫–æ–≤–∏—Ö —Å—Ç–∞—Ç–µ–π —Ç–∞ —Ä–µ—Å—É—Ä—Å—ñ–≤.

## Vanilla Vision Transformer

ViT --- —Ü–µ –º–æ–¥–µ–ª—å –≥–ª–∏–±–æ–∫–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è, —è–∫–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å. –í–æ–Ω–∞ –±—É–ª–∞ –∑–∞–ø—Ä–æ–ø–æ–Ω–æ–≤–∞–Ω–∞ –≤ —Å—Ç–∞—Ç—Ç—ñ ["An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"](https://arxiv.org/abs/2010.11929) (Dosovitskiy et al., 2020).

---

![ViT Architecture](img/vit.gif)

## –°—Ç–∞—Ä—Ç—É—î–º–æ... {.smaller}

```{python}
import torch
import torchvision
print(f"torch version: {torch.__version__}")
print(f"torchvision version: {torchvision.__version__}")

import matplotlib.pyplot as plt

from torch import nn
from torchvision import transforms
from torchinfo import summary
from going_modular.going_modular import data_setup, engine
from helper_functions import download_data, set_seeds, plot_loss_curves

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

from pathlib import Path
data_path = Path("going_modular/")
train_dir = data_path / "pizza_steak_sushi/train"
test_dir = data_path / "pizza_steak_sushi/test"
```

## Datasets —Ç–∞ DataLoaders

- –§—É–Ω–∫—Ü—ñ—è `create_dataloaders()` —É —Ñ–∞–π–ª—ñ `going_modular/going_modular.py` —Å—Ç–≤–æ—Ä—é—î DataLoaders –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–≥–æ —Ç–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä—ñ–≤ –¥–∞–Ω–∏—Ö.
- –ê–ª–µ —Å–ø–æ—á–∞—Ç–∫—É –ø–æ—Ç—Ä—ñ–±–Ω–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º—É–≤–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è. –î–∏–≤. [—Ç–∞–±–ª–∏—Ü—é 3](https://arxiv.org/pdf/2010.11929).

![](img/vif-01.jpg)

## –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó

```{python}
IMG_SIZE = 224

manual_transforms = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
])
print(f"Manually created transforms: {manual_transforms}")
```

## –ü–µ—Ä–µ–¥–∞—î–º–æ —É DataLoader

- –†–æ–∑–º—ñ—Ä –±–∞—Ç—á—É —É —Å—Ç–∞—Ç—ñ - 4096, –∞–ª–µ —É –Ω–∞—Å –º–æ–∂–µ –Ω–µ –±—É—Ç–∏ —Å—Ç—ñ–ª—å–∫–∏ –ø–∞–º'—è—Ç—ñ.
- –í–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ 32.
- –Ø–∫—â–æ –≤—Å–µ –æ–∫, –º–æ–∂–Ω–∞ –∑–±—ñ–ª—å—à–∏—Ç–∏.

```{python}
BATCH_SIZE = 32

train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(
    train_dir=train_dir,
    test_dir=test_dir,
    transform=manual_transforms,
    batch_size=BATCH_SIZE,
    num_workers=0
)

train_dataloader, test_dataloader, class_names
```

## –í—Ö–æ–¥–∏, –≤–∏—Ö–æ–¥–∏, —à–∞—Ä–∏ —Ç–∞ –±–ª–æ–∫–∏

- –í—Ö—ñ–¥: –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ —Ç—Ä—å–æ–º–∞ –∫–ª–∞—Å–∞–º–∏ (–ø—ñ—Ü–∞, —Å—Ç–µ–π–∫, —Å—É—à—ñ).
- –í–∏—Ö—ñ–¥: –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –Ω–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –¥–æ –∫–æ–∂–Ω–æ–≥–æ –∑ —Ç—Ä—å–æ—Ö –∫–ª–∞—Å—ñ–≤.
- –®–∞—Ä–∏: –ø—Ä–∏–π–º–∞—î –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ, –≤–∏–∫–æ–Ω—É—î –æ–±—á–∏—Å–ª–µ–Ω–Ω—è —Ç–∞ –ø–µ—Ä–µ–¥–∞—î –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –Ω–∞—Å—Ç—É–ø–Ω–æ–º—É —à–∞—Ä—É.
- –ë–ª–æ–∫–∏: —Å—É–∫—É–ø–Ω—ñ—Å—Ç—å —à–∞—Ä—ñ–≤, —è–∫—ñ –ø—Ä–∞—Ü—é—é—Ç—å —Ä–∞–∑–æ–º –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –ø–µ–≤–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó.
- –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ (–º–æ–¥–µ–ª—å): —Å—É–∫—É–ø–Ω—ñ—Å—Ç—å –±–ª–æ–∫—ñ–≤, —è–∫—ñ –ø—Ä–∞—Ü—é—é—Ç—å —Ä–∞–∑–æ–º –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è —Å–∫–ª–∞–¥–Ω–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è.

---

::: {.columns}
::: {.column}
```{mermaid}
%%| echo: false
graph LR
    A[Inputs] --> B{Layer};
    B --> C[Outputs];
    
    subgraph " "
        direction TB
        D["<b>Attention(Q, K, V) = softmax(QK<sup>T</sup>/‚àöd<sub>k</sub>)V"]
    end

    B-.->D
    
    style B fill:#7FFFD4,stroke:#7FFFD4,color:#000
    style D fill:#000,stroke:#000,color:#fff
```
:::
::: {.column}
```{mermaid}
%%| echo: false
graph LR
    Inputs --> L1;

    subgraph Block
        direction LR
        L1[Layer]
        L2[Layer]
        L3[Layer]
    end
    
    L3 --> Outputs;
    
    style Block fill:#1E90FF,stroke:#1E90FF,color:white
    style L1 fill:#7FFFD4,stroke:#7FFFD4,color:#000
    style L2 fill:#7FFFD4,stroke:#7FFFD4,color:#000
    style L3 fill:#7FFFD4,stroke:#7FFFD4,color:#000
```
:::
:::

---

```{mermaid}
%%| echo: false
graph LR
    Inputs --> Model;
    subgraph Model
        direction LR
        subgraph Block_1
            direction LR
            L1[Layer]
            L2[Layer]
            L3[Layer]
        end
        subgraph Block_2
            direction LR
            L4[Layer]
            L5[Layer]
            L6[Layer]
        end
        etc[...]
    end
    Model --> Outputs;

    style Model fill:#FA8072,stroke:#FA8072,color:white
    style Block_1 fill:#1E90FF,stroke:#1E90FF,color:white
    style Block_2 fill:#1E90FF,stroke:#1E90FF,color:white
    style L1 fill:#7FFFD4,stroke:#7FFFD4,color:#000
    style L2 fill:#7FFFD4,stroke:#7FFFD4,color:#000
    style L3 fill:#7FFFD4,stroke:#7FFFD4,color:#000
    style L4 fill:#7FFFD4,stroke:#7FFFD4,color:#000
    style L5 fill:#7FFFD4,stroke:#7FFFD4,color:#000
    style L6 fill:#7FFFD4,stroke:#7FFFD4,color:#000
```

## –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ Vision Transformer {.smaller}

- –†–∏—Å—É–Ω–æ–∫ 1.: –ì—Ä–∞—Ñ—ñ—á–Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ ViT.
- –§–æ—Ä–º—É–ª–∏ 1-4 —É —Ä–æ–∑–¥—ñ–ª—ñ 3.1: –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤ ViT.
- –¢–∞–±–ª–∏—Ü—è 1: –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–æ–¥–µ–ª—ñ ViT.

::: {layout-ncol=3}

![](img/vif-02.jpg)

![](img/vif-03.jpg)

![](img/vif-04.jpg)

:::

## –†–∏—Å—É–Ω–æ–∫ 1 {.tiny}

- **Patch + Position Embedding** (–≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ) - –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–æ–∑–±–∏–≤–∞—î—Ç—å—Å—è –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏ (patches) –∑ –¥–æ–¥–∞–≤–∞–Ω–Ω—è–º —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –ø–æ–∑–∏—Ü—ñ—é (position embeddings).
- **Linear projection of flattened patches (Embedded Patches)** - –§—Ä–∞–≥–º–µ–Ω—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—é—Ç—å—Å—è –Ω–∞ –µ–º–±–µ–Ω–¥—ñ–Ω–≥–∏.
- **Norm** - —Ü–µ —Å–∫–æ—Ä–æ—á–µ–Ω–Ω—è –≤—ñ–¥ ¬´Layer Normalization¬ª –∞–±–æ ¬´LayerNorm¬ª, —Ç–µ—Ö–Ω—ñ–∫–∏ –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó (–∑–º–µ–Ω—à–µ–Ω–Ω—è –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è) –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂—ñ (`torch.nn.LayerNorm()`).
- **Multi-Head Attention** - —Ü–µ —à–∞—Ä Multi-Headed Self-Attention –∞–±–æ, —Å–∫–æ—Ä–æ—á–µ–Ω–æ, ¬´MSA¬ª (`torch.nn.MultiheadAttention()`).
- **MLP** (–∞–±–æ –±–∞–≥–∞—Ç–æ—à–∞—Ä–æ–≤–∏–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω) ‚Äî MLP —á–∞—Å—Ç–æ –º–æ–∂–µ –æ–∑–Ω–∞—á–∞—Ç–∏ –±—É–¥—å-—è–∫—É —Å—É–∫—É–ø–Ω—ñ—Å—Ç—å —à–∞—Ä—ñ–≤ –ø—Ä—è–º–æ–≥–æ –ø–æ—à–∏—Ä–µ–Ω–Ω—è (–∞–±–æ, —É –≤–∏–ø–∞–¥–∫—É PyTorch, —Å—É–∫—É–ø–Ω—ñ—Å—Ç—å —à–∞—Ä—ñ–≤ –∑ –º–µ—Ç–æ–¥–æ–º `forward()`). –£ —Å—Ç–∞—Ç—Ç—ñ –ø—Ä–æ ViT –∞–≤—Ç–æ—Ä–∏ –Ω–∞–∑–∏–≤–∞—é—Ç—å MLP ¬´–±–ª–æ–∫–æ–º MLP¬ª, —è–∫–∏–π –º—ñ—Å—Ç–∏—Ç—å –¥–≤–∞ —à–∞—Ä–∏ `torch.nn.Linear()` –∑ –Ω–µ–ª—ñ–Ω—ñ–π–Ω–æ—é –∞–∫—Ç–∏–≤–∞—Ü—ñ—î—é `torch.nn.GELU()` –º—ñ–∂ –Ω–∏–º–∏ —ñ —à–∞—Ä `torch.nn.Dropout()` –ø—ñ—Å–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑ –Ω–∏—Ö.
- **Transformer Encoder** ‚Äî —Ü–µ —Å—É–∫—É–ø–Ω—ñ—Å—Ç—å —à–∞—Ä—ñ–≤, –ø–µ—Ä–µ—Ä–∞—Ö–æ–≤–∞–Ω–∏—Ö –≤–∏—â–µ. –ó–∞–≥–∞–ª—å–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ ViT —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –∑ –¥–µ–∫—ñ–ª—å–∫–æ—Ö Transformer encoders, —Ä–æ–∑—Ç–∞—à–æ–≤–∞–Ω–∏—Ö –æ–¥–∏–Ω –Ω–∞–¥ –æ–¥–Ω–∏–º. –°–∏–º–≤–æ–ª "+" –Ω–∞ –º–∞–ª—é–Ω–∫—É –≤–∫–∞–∑—É—î –Ω–∞ —Ç–µ, —â–æ –≤–∏—Ö—ñ–¥ –æ–¥–Ω–æ–≥–æ Transformer encoder —î –≤—Ö–æ–¥–æ–º –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ.
- **MLP Head** ‚Äî —Ü–µ –≤–∏—Ö—ñ–¥–Ω–∏–π —à–∞—Ä –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏, —è–∫–∏–π –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î –≤–∏–≤—á–µ–Ω—ñ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –∫–ª–∞—Å—É.

## Patch + Position Embedding

```{python}
height = 224 # H
width = 224 # W
color_channels = 3 # C
patch_size = 16 # P

number_of_patches = int((height * width) / patch_size**2)
print(f"Number of patches: {number_of_patches}")
```

## Patch + Position Embedding

- **–í—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ:** –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Å–ø–æ—á–∞—Ç–∫—É –º–∞—î –≤–∏–≥–ª—è–¥ 2D —Ä–æ–∑–º—ñ—Ä–æ–º ${H \times W \times C}$.
- **–í–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ:** –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å —Å–ø–ª–æ—â–µ–Ω–∏—Ö 2D —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ñ–≤ —Ä–æ–∑–º—ñ—Ä–æ–º ${N \times\left(P^{2} \cdot C\right)}$.

```{python}
embedding_layer_input_shape = (height, width, color_channels)

embedding_layer_output_shape = (number_of_patches, patch_size**2 * color_channels)

print(f"Input shape (single 2D image): {embedding_layer_input_shape}")
print(f"Output shape (single 2D image flattened into patches): {embedding_layer_output_shape}")
```

## –Ø–∫ —Ü–µ –≤–∏–≥–ª—è–¥–∞—î?

```{python}
#| output-location: column
# Get a batch of images
image_batch, label_batch = next(iter(train_dataloader))

# Get a single image from the batch
image, label = image_batch[0], label_batch[0]

# View the batch shapes
print(image.shape, label)

plt.imshow(image.permute(1, 2, 0)) # adjust for matplotlib
plt.title(class_names[label])
plt.axis(False);
```

## –Ø–∫ —Ü–µ –≤–∏–≥–ª—è–¥–∞—î?

```{python}
#| output-location: column

image_permuted = image.permute(1, 2, 0)

# Index to plot the top row of patched pixels
patch_size = 16
plt.figure(figsize=(patch_size, patch_size))
plt.imshow(image_permuted[:patch_size, :, :]);
```

## –Ø–∫ —Ü–µ –≤–∏–≥–ª—è–¥–∞—î? {.tiny}

```{python}
# | output-location: slide
img_size = 224
patch_size = 16
num_patches = img_size/patch_size
assert img_size % patch_size == 0, "Image size must be divisible by patch size"
print(f"Number of patches per row: {num_patches}\nPatch size: {patch_size} pixels x {patch_size} pixels")

fig, axs = plt.subplots(nrows=1,
                        ncols=img_size // patch_size,
                        figsize=(num_patches, num_patches),
                        sharex=True,
                        sharey=True)

for i, patch in enumerate(range(0, img_size, patch_size)):
    axs[i].imshow(image_permuted[:patch_size, patch:patch+patch_size, :]);
    axs[i].set_xlabel(i+1)
    axs[i].set_xticks([])
    axs[i].set_yticks([])
```

## –Ø–∫ —Ü–µ –≤–∏–≥–ª—è–¥–∞—î?

```{python}
# | output-location: slide

img_size = 224
patch_size = 16
num_patches = img_size/patch_size
assert img_size % patch_size == 0, "Image size must be divisible by patch size"
print(f"Number of patches per row: {num_patches}\
        \nNumber of patches per column: {num_patches}\
        \nTotal patches: {num_patches*num_patches}\
        \nPatch size: {patch_size} pixels x {patch_size} pixels")

fig, axs = plt.subplots(nrows=img_size // patch_size,
                        ncols=img_size // patch_size,
                        figsize=(num_patches, num_patches),
                        sharex=True,
                        sharey=True)

for i, patch_height in enumerate(range(0, img_size, patch_size)):
    for j, patch_width in enumerate(range(0, img_size, patch_size)):

        axs[i, j].imshow(image_permuted[patch_height:patch_height+patch_size,
                                        patch_width:patch_width+patch_size,
                                        :])

        axs[i, j].set_ylabel(i+1,
                             rotation="horizontal",
                             horizontalalignment="right",
                             verticalalignment="center")
        axs[i, j].set_xlabel(j+1)
        axs[i, j].set_xticks([])
        axs[i, j].set_yticks([])
        axs[i, j].label_outer()

fig.suptitle(f"{class_names[label]} -> Patchified", fontsize=16)
plt.show()
```

## `torch.nn.Conv2d()` {.smaller}

- –ú–∏ –º–æ–∂–µ–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ `torch.nn.Conv2d()` –¥–ª—è —Ä–æ–∑–±–∏—Ç—Ç—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏ (patches).
- –ü–∞—Ä–∞–º–µ—Ç—Ä–∏:
    - `in_channels`: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–∞–Ω–∞–ª—ñ–≤ —É –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö (3 –¥–ª—è RGB-–∑–æ–±—Ä–∞–∂–µ–Ω—å).
    - `out_channels`: –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ñ—ñ–ª—å—Ç—Ä—ñ–≤ (–ø–æ—Ç—Ä—ñ–±–Ω–æ –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ —Ä—ñ–≤–Ω–∏–º —Ä–æ–∑–º—ñ—Ä—É –µ–º–±–µ–¥—ñ–Ω–≥—É, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 768).
    - `kernel_size`: —Ä–æ–∑–º—ñ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (patch size), –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 16.
    - `stride`: –∫—Ä–æ–∫ –∫–æ–≤–∑–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä–∞ (stride), —Ç–∞–∫–æ–∂ –≤—Å—Ç–∞–Ω–æ–≤–ª—é—î—Ç—å—Å—è —Ä—ñ–≤–Ω–∏–º —Ä–æ–∑–º—ñ—Ä—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞.
    - `padding`: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—ñ–∫—Å–µ–ª—ñ–≤, —è–∫—ñ –¥–æ–¥–∞—é—Ç—å—Å—è –¥–æ –∫—Ä–∞—ó–≤ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (0 –¥–ª—è –±–µ–∑ –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ –ø–∞–¥–¥—ñ–Ω–≥—É).

```{python}
from torch import nn

patch_size=16

conv2d = nn.Conv2d(in_channels=3, 
                   out_channels=768,
                   kernel_size=patch_size,
                   stride=patch_size,
                   padding=0)
```

---

```{python}
# View single image
plt.imshow(image.permute(1, 2, 0)) # adjust for matplotlib
plt.title(class_names[label])
plt.axis(False);

image_out_of_conv = conv2d(image.unsqueeze(0))
print(image_out_of_conv.shape)
```

---

–í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –ø—ñ—Å–ª—è —à–∞—Ä—É `Conv2d`

```{python}
import random
random_indexes = random.sample(range(0, 758), k=5)
print(f"Showing random convolutional feature maps from indexes: {random_indexes}")

fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(12, 12))

for i, idx in enumerate(random_indexes):
    image_conv_feature_map = image_out_of_conv[:, idx, :, :]
    axs[i].imshow(image_conv_feature_map.squeeze().detach().numpy())
    axs[i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[]);
```

---

–ü–µ—Ä–µ–≥–ª—è–Ω–µ–º–æ –æ–∫—Ä–µ–º—É –æ–∑–Ω–∞–∫—É –≤ —Ç–µ–Ω–∑–æ—Ä–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ

```{python}
# Get a single feature map in tensor form
single_feature_map = image_out_of_conv[:, 0, :, :]
single_feature_map, single_feature_map.requires_grad
```

## `torch.nn.Flatten()` {.tiny}

–ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –ø—ñ—Å–ª—è —à–∞—Ä—É `Conv2d` —É —Ñ–æ—Ä–º–∞—Ç, –ø—Ä–∏–¥–∞—Ç–Ω–∏–π –¥–ª—è –ª—ñ–Ω—ñ–π–Ω–æ–≥–æ —à–∞—Ä—É

```{python}
# Current tensor shape
print(f"Current tensor shape: {image_out_of_conv.shape} -> [batch, embedding_dim, feature_map_height, feature_map_width]")
```

- `start_dim=2`: –ø–æ—á–∏–Ω–∞—î–º–æ —Å–ø–ª–æ—â–µ–Ω–Ω—è –∑ —Ç—Ä–µ—Ç—å–æ–≥–æ –≤–∏–º—ñ—Ä—É (—ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—è –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ 0).
- `end_dim=3`: –∑–∞–∫—ñ–Ω—á—É—î–º–æ —Å–ø–ª–æ—â–µ–Ω–Ω—è –Ω–∞ —á–µ—Ç–≤–µ—Ä—Ç–æ–º—É –≤–∏–º—ñ—Ä—ñ.

```{python}

flatten = nn.Flatten(start_dim=2,
                     end_dim=3)
```

## –í—Å–µ —Ä–∞–∑–æ–º {.tiny}

1. –ë–µ—Ä–µ–º–æ –æ–¥–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.
2. –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –π–æ–≥–æ —á–µ—Ä–µ–∑ –∫–æ–Ω–≤–æ–ª—é—Ü—ñ–π–Ω–∏–π —à–∞—Ä (conv2d), —â–æ–± –ø–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–∞ 2D-–∫–∞—Ä—Ç–∏ –æ–∑–Ω–∞–∫ (–≤–±—É–¥–æ–≤—É–≤–∞–Ω–Ω—è –ø–∞—Ç—á—ñ–≤).
3. –°–ø–ª–∞–≤–∏—Ç–∏ 2D-–∫–∞—Ä—Ç—É –æ–∑–Ω–∞–∫ –≤ –æ–¥–Ω—É –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å.

```{python}
#| output-location: slide
plt.imshow(image.permute(1, 2, 0))
plt.title(class_names[label])
plt.axis(False);
print(f"Original image shape: {image.shape}")

image_out_of_conv = conv2d(image.unsqueeze(0))
print(f"Image feature map shape: {image_out_of_conv.shape}")

image_out_of_conv_flattened = flatten(image_out_of_conv)
print(f"Flattened image feature map shape: {image_out_of_conv_flattened.shape}")
```

## `torch.Tensor.permute()`

- –ü—ñ—Å–ª—è —Å–ø–ª–æ—â–µ–Ω–Ω—è, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ –æ—Å—Ç–∞—Ç–æ—á–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –µ–º–±–µ–¥—ñ–Ω–≥—É –ø–∞—Ç—á—ñ–≤, –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–º—ñ–Ω–∏—Ç–∏ –ø–æ—Ä—è–¥–æ–∫ –≤–∏–º—ñ—Ä—ñ–≤ —Ç–µ–Ω–∑–æ—Ä–∞.

```{python}
image_out_of_conv_flattened_reshaped = image_out_of_conv_flattened.permute(0, 2, 1)
print(f"Patch embedding sequence shape: {image_out_of_conv_flattened_reshaped.shape} -> [batch_size, num_patches, embedding_size]")
```

---

–í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ –æ–∫—Ä–µ–º—É –æ–∑–Ω–∞–∫—É –ø—ñ—Å–ª—è —Å–ø–ª–æ—â–µ–Ω–Ω—è

```{python}
single_flattened_feature_map = image_out_of_conv_flattened_reshaped[:, :, 0]
plt.figure(figsize=(22, 22))
plt.imshow(single_flattened_feature_map.detach().numpy())
plt.title(f"Flattened feature map shape: {single_flattened_feature_map.shape}")
plt.axis(False);
```

---

–ü–µ—Ä–µ–≥–ª—è–Ω–µ–º–æ –æ–∫—Ä–µ–º—É –æ–∑–Ω–∞–∫—É —É —Ç–µ–Ω–∑–æ—Ä–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ

```{python}
single_flattened_feature_map, single_flattened_feature_map.requires_grad, single_flattened_feature_map.shape
```

# –î—è–∫—É—é –∑–∞ —É–≤–∞–≥—É! {.unnumbered .unlisted background-iframe=".07_files/libs/colored-particles/index.html"}

<br> <br>

{{< iconify solar book-bold >}} [–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ –∫—É—Ä—Å—É](https://aranaur.rbind.io/lectures/)

{{< iconify mdi envelope >}} ihor.miroshnychenko\@knu.ua

{{< iconify ic baseline-telegram >}} [Data Mirosh](https://t.me/araprof)

{{< iconify mdi linkedin >}} [\@ihormiroshnychenko](https://www.linkedin.com/in/ihormiroshnychenko/)

{{< iconify mdi github >}} [\@aranaur](https://github.com/Aranaur)

{{< iconify ion home >}} [aranaur.rbind.io](https://aranaur.rbind.io)
